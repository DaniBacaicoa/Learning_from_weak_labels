{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation\n",
    "\n",
    "This notebook serves as a common dataset creator. \n",
    "\n",
    "We will create a corrupted version of MNIST acording to the scheme of partial labels.\n",
    "\n",
    "This dataset will serve to compare every loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import datasets.datasets as dtset\n",
    "import utils.losses as losses\n",
    "\n",
    "from utils.weakener import Weakener\n",
    "from models.model import MLP\n",
    "\n",
    "from utils.trainig_testing import train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = dtset.Torch_Dataset('mnist', batch_size = 16)\n",
    "Weak = Weakener(Data.num_classes)\n",
    "Weak.generate_M(model_class='pll',pll_p=0.2)\n",
    "train_X,train_y,test_X,test_y =  Data.get_data()\n",
    "Weak.generate_weak(train_y) #z and w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Dataset = [Data,Weak]\n",
    "f = open(\"Experimental_results/Datasets.pkl\",\"wb\")\n",
    "pickle.dump(Dataset,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
