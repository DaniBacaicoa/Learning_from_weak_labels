{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Quick example of WL Classification\n",
    "## using Valen's warm up and our virtual label model\n",
    "This example tries to show the usage of the classes and methods\n",
    "proposed here to show classification with weakly labeled datasets.\n",
    "\n",
    "We will use the model proposed by Valen and their warm up prior to 20 epochs\n",
    "with our method (We will use the"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Importing general libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Importing specific classes and functions\n",
    "from utils.weakener import Weakener\n",
    "\n",
    "#Importing drawing tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing dataloaders\n",
    "from datasets.openml_datasets import OpenML_Dataset\n",
    "from datasets.torch_datasets import Torch_Dataset\n",
    "from models.model import MLP,mlp_valen\n",
    "from utils.trainig_testing import train_model,evaluate_model,train_and_evaluate\n",
    "from utils.losses import EMLoss, CELoss, PartialLoss,OSLCELoss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# DS stores the dataset and its related attributes\n",
    "DS = Torch_Dataset('mnist')\n",
    "train_x, train_y, test_x, test_y = DS.get_data()\n",
    "# WL stores pocesses relative to the Weakening process\n",
    "WL = Weakener(DS.num_classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Generation of the mixing matrix according to the model\n",
    "#  we've chosen.\n",
    "WL.generate_M(model_class='pll')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# We generate the weak labels (this step is optional as WL.virtual_labels(train_y) can do it)\n",
    "z, w = WL.generate_weak(train_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "z is the numerical encodig of the weak label while w is a one-hot\n",
    "representation of that variable. z also encodes the row of the M matrix\n",
    "for that given weak label.\n",
    "\n",
    "Let's consider the example of partial label learning for the iris dataset.\n",
    "labels are encoded as ```{0: '011', 1: '101', 2: '110', 3: '111'}```\n",
    "so having an isntance with `z=3` means `w=[1,1,1]`, i.e., the weak label contains every label."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# We generate the weak labels (this step is optional as WL.virtual_labels(train_y) can do it)\n",
    "WL.virtual_matrix()\n",
    "#And we generate the virtual labels\n",
    "WL.virtual_labels(train_y)\n",
    "\n",
    "\n",
    "#we make a new dataloader because valen takes the weak label instead of the\n",
    "# virtual label.\n",
    "indices = torch.arange(0,len(train_x))\n",
    "valen_train_data = TensorDataset(train_x, w ,train_y, indices)\n",
    "valen_train_loader = DataLoader(valen_train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "WL.virtual_labels(train_y)\n",
    "DS.include_weak(WL.v)\n",
    "# Once we have our dataset with all the labels we need we can create the dataloaders.\n",
    "trainloader, testloader = DS.get_dataloader()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "mlp = MLP(input_size=DS.num_features, hidden_sizes=[DS.num_features,DS.num_features,DS.num_features],\n",
    "          output_size=DS.num_classes, dropout_p=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 1.2057 - Accuracy: 0.7010\n",
      "Epoch 2/10 - Loss: 0.1800 - Accuracy: 0.9153\n",
      "Epoch 3/10 - Loss: 0.1334 - Accuracy: 0.9358\n",
      "Epoch 4/10 - Loss: 0.1153 - Accuracy: 0.9429\n",
      "Epoch 5/10 - Loss: 0.1015 - Accuracy: 0.9497\n",
      "Epoch 6/10 - Loss: 0.0928 - Accuracy: 0.9519\n",
      "Epoch 7/10 - Loss: 0.0952 - Accuracy: 0.9523\n",
      "Epoch 8/10 - Loss: 0.0778 - Accuracy: 0.9592\n",
      "Epoch 9/10 - Loss: 0.0904 - Accuracy: 0.9562\n",
      "Epoch 10/10 - Loss: 0.0771 - Accuracy: 0.9604\n"
     ]
    }
   ],
   "source": [
    "#optimizer = torch.optim.SGD(mlp.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_fn_bk = OSLCELoss()\n",
    "\n",
    "_,_,mlp =  train_model(mlp,valen_train_loader, optimizer, loss_fn_bk,num_epochs=10, return_model=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 0, 4,  ..., 5, 6, 8])\n",
      "torch.Size([60000, 10])\n",
      "torch.Size([60000, 784])\n",
      "torch.Size([60000, 10])\n",
      "torch.Size([60000, 10])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "#Lets try with the values predicted from that model\n",
    "_,train_y_new = torch.max(nn.functional.softmax(mlp(train_x),dim=1),dim=1)\n",
    "print(train_y_new)\n",
    "train_y_new = torch.eye(DS.num_classes)[train_y_new]\n",
    "print(train_y_new.shape)\n",
    "WL2 = Weakener(DS.num_classes)\n",
    "WL2.generate_M(model_class='pll',pll_p=0.5)\n",
    "\n",
    "z2, w2 = WL2.generate_weak(train_y_new)\n",
    "WL2.virtual_matrix()\n",
    "#And we generate the virtual labels\n",
    "WL2.virtual_labels(train_y_new)\n",
    "indices = torch.arange(0,len(train_x))\n",
    "print(train_x.shape)\n",
    "print(torch.tensor(WL2.v).shape)\n",
    "print(train_y_new.shape)\n",
    "print(indices.shape)\n",
    "\n",
    "new_train_data = TensorDataset(train_x, torch.tensor(WL2.v) ,train_y_new, indices)\n",
    "new_train_loader = DataLoader(new_train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "new_test_data = TensorDataset(test_x, test_y)\n",
    "new_test_loader = DataLoader(new_test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "mlp2 = MLP(input_size=DS.num_features, hidden_sizes=[DS.num_features,DS.num_features,DS.num_features],\n",
    "          output_size=DS.num_classes, dropout_p=0.5, bn=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: Train Loss: 3.1698, Train Acc: 0.1047, Test Acc: 0.1031\n",
      "Epoch 2/30: Train Loss: 3.1705, Train Acc: 0.1035, Test Acc: 0.1018\n",
      "Epoch 3/30: Train Loss: 3.1536, Train Acc: 0.1037, Test Acc: 0.1013\n",
      "Epoch 4/30: Train Loss: 3.1658, Train Acc: 0.1042, Test Acc: 0.1029\n",
      "Epoch 5/30: Train Loss: 3.1712, Train Acc: 0.1017, Test Acc: 0.1016\n",
      "Epoch 6/30: Train Loss: 3.1646, Train Acc: 0.1037, Test Acc: 0.1016\n",
      "Epoch 7/30: Train Loss: 3.1763, Train Acc: 0.1034, Test Acc: 0.1021\n",
      "Epoch 8/30: Train Loss: 3.1468, Train Acc: 0.1040, Test Acc: 0.0980\n",
      "Epoch 9/30: Train Loss: 3.1529, Train Acc: 0.1039, Test Acc: 0.1003\n",
      "Epoch 10/30: Train Loss: 3.1626, Train Acc: 0.1026, Test Acc: 0.1007\n",
      "Epoch 11/30: Train Loss: 3.1652, Train Acc: 0.1043, Test Acc: 0.0989\n"
     ]
    }
   ],
   "source": [
    "# Define the optimizer and loss function\n",
    "mlp2 = MLP(input_size=DS.num_features, hidden_sizes=[DS.num_features,DS.num_features,DS.num_features],\n",
    "          output_size=DS.num_classes, dropout_p=0.5, bn=True)\n",
    "loss_fn = CELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "mlp2, results = train_and_evaluate(mlp2, new_train_loader, new_test_loader,\n",
    "                                  optimizer, loss_fn, num_epochs=30)\n",
    "\n",
    "# Print the results\n",
    "print('Train Loss:', results['train_loss'][-1])\n",
    "print('Train Accuracy:', results['train_acc'][-1])\n",
    "print('Test Accuracy:', results['test_acc'][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0].plot(results['train_loss'])\n",
    "axis[0].set_title(\"Train_loss\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[1].plot(results['train_acc'])\n",
    "axis[1].plot(results['test_acc'])\n",
    "axis[1].set_title(\"Accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#We need to include this Weak Labels into the dataset,\n",
    "# we need to include w to mantain the coherence. z will only be used\n",
    "# in the loss for the EM\n",
    "DS.include_weak(WL.v)\n",
    "# Once we have our dataset with all the labels we need we can create the dataloaders.\n",
    "trainloader, testloader = DS.get_dataloader()\n",
    "\n",
    "print(len(testloader.dataset))\n",
    "print(len(trainloader.dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a trainloader containing (X,v,y) and a testloader containig (X,y)\n",
    "so we can just establish our model and train it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an instance of the MLP class\n",
    "mlp = MLP(input_size=DS.num_features, hidden_sizes=[20],\n",
    "          output_size=DS.num_classes, dropout_p=0.5)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_fn = CELoss()\n",
    "\n",
    "train_losses,train_accs=train_model(mlp,trainloader,optimizer,\n",
    "                                    loss_fn,num_epochs=10)\n",
    "\n",
    "# Print the final training loss and accuracy\n",
    "print('Final Training Loss: {:.4f}'.format(train_losses[-1]))\n",
    "print('Final Training Accuracy: {:.4f}'.format(train_accs[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0].plot(train_losses)\n",
    "axis[0].set_title(\"Train_loss\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[1].plot(train_accs)\n",
    "axis[1].set_title(\"Train_accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an instance of the MLP class\n",
    "mlp = MLP(input_size=DS.num_features, hidden_sizes=[20],\n",
    "          output_size=DS.num_classes, dropout_p=0.5)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_fn = CELoss()\n",
    "\n",
    "# Train and evaluate the MLP on the training data, test data, and get the results\n",
    "mlp, results = train_and_evaluate(mlp, trainloader, testloader,\n",
    "                                  optimizer, loss_fn, num_epochs=10)\n",
    "\n",
    "# Print the results\n",
    "print('Train Loss:', results['train_loss'][-1])\n",
    "print('Train Accuracy:', results['train_acc'][-1])\n",
    "print('Test Accuracy:', results['test_acc'][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0].plot(results['train_loss'])\n",
    "axis[0].set_title(\"Train_loss\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[1].plot(results['train_acc'])\n",
    "axis[1].plot(results['test_acc'])\n",
    "axis[1].set_title(\"Accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2fb0f616",
   "language": "python",
   "display_name": "PyCharm (Learning_from_weak_labels)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}