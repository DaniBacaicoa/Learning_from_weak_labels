{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets.openml_datasets import OpenML_Dataset\n",
    "from datasets.torch_datasets import Torch_Dataset\n",
    "from utils.weakener import Weakener\n",
    "from models.general_model import MLP\n",
    "from utils.losses import PartialLoss,LBLoss,EMLoss,OSLCELoss,OSLBrierLoss,CELoss\n",
    "from utils.trainig_testing import train_model,evaluate_model,train_and_evaluate,ES_train_and_evaluate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = 'mnist'\n",
    "weakening = 'random' #for possible ['random','feature']\n",
    "\n",
    "Data = Torch_Dataset(dataset, batch_size=256)\n",
    "Weak = Weakener(Data.num_classes)\n",
    "Weak.generate_M('pll',pll_p=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([241, 950, 924,  ..., 783, 832, 864], dtype=torch.int32),\n tensor([[0., 0., 1.,  ..., 0., 1., 0.],\n         [1., 1., 1.,  ..., 0., 0., 1.],\n         [1., 1., 1.,  ..., 1., 1., 1.],\n         ...,\n         [1., 1., 0.,  ..., 0., 1., 0.],\n         [1., 1., 0.,  ..., 0., 1., 1.],\n         [1., 1., 0.,  ..., 0., 1., 1.]], dtype=torch.float64))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X,train_y,test_X,test_y =  Data.get_data()\n",
    "print(train_X.shape)\n",
    "Weak.generate_weak(train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "mlp_feature = MLP(Data.num_features, [Data.num_features, Data.num_features, Data.num_features], Data.num_classes, dropout_p = 0.0, bn = False, seed = 1,\n",
    "                  layer_init = lambda x: nn.init.kaiming_uniform_(x, a=math.sqrt(5)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['layers.0.weight', 'layers.0.bias', 'layers.1.weight', 'layers.1.bias', 'layers.2.weight', 'layers.2.bias', 'layers.3.weight', 'layers.3.bias'])\n",
      "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(mlp_feature.state_dict().keys())\n",
    "\n",
    "valen_weights = torch.load('results/mnist_random')\n",
    "print(valen_weights.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "tensor([[ 0.0172, -0.0161, -0.0075,  ...,  0.0059, -0.0047,  0.0017],\n",
      "        [-0.0267, -0.0219, -0.0302,  ..., -0.0029,  0.0012, -0.0163],\n",
      "        [ 0.0275, -0.0093, -0.0333,  ..., -0.0138,  0.0055, -0.0328],\n",
      "        ...,\n",
      "        [-0.0015, -0.0159, -0.0231,  ..., -0.0109,  0.0195, -0.0093],\n",
      "        [ 0.0065,  0.0274, -0.0327,  ...,  0.0053,  0.0243,  0.0175],\n",
      "        [-0.0229, -0.0293,  0.0004,  ..., -0.0110,  0.0073, -0.0074]])\n",
      "layers.0.weight\n",
      "tensor([[ 0.0035,  0.0052,  0.0204,  ...,  0.0049,  0.0135, -0.0151],\n",
      "        [ 0.0047, -0.0078,  0.0343,  ..., -0.0142, -0.0098,  0.0058],\n",
      "        [-0.0316, -0.0248, -0.0252,  ..., -0.0233, -0.0335,  0.0179],\n",
      "        ...,\n",
      "        [-0.0104,  0.0225, -0.0054,  ..., -0.0116, -0.0109, -0.0114],\n",
      "        [-0.0007, -0.0176, -0.0028,  ..., -0.0159,  0.0323,  0.0165],\n",
      "        [ 0.0004, -0.0072,  0.0057,  ...,  0.0117, -0.0161, -0.0064]])\n"
     ]
    }
   ],
   "source": [
    "# We see that the mlp parameters and the weights taken from valen are initially different\n",
    "w = 'layers.0.weight'\n",
    "w1 = w.split('.')\n",
    "name = 'fc'+str(int(w1[1])+1)+'.'+w1[2]\n",
    "print(name)\n",
    "print(valen_weights[name])\n",
    "print(w)\n",
    "print(mlp_feature.state_dict()[w])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def weight_allocation(net,weights):\n",
    "    for name, param in net.named_parameters():\n",
    "        w = name.split('.')\n",
    "        w_name = 'fc'+str(int(w[1])+1)+'.'+w[2]\n",
    "        param.data = weights[w_name]\n",
    "    return net\n",
    "mlp_feature = weight_allocation(mlp_feature,valen_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "tensor([[ 0.0172, -0.0161, -0.0075,  ...,  0.0059, -0.0047,  0.0017],\n",
      "        [-0.0267, -0.0219, -0.0302,  ..., -0.0029,  0.0012, -0.0163],\n",
      "        [ 0.0275, -0.0093, -0.0333,  ..., -0.0138,  0.0055, -0.0328],\n",
      "        ...,\n",
      "        [-0.0015, -0.0159, -0.0231,  ..., -0.0109,  0.0195, -0.0093],\n",
      "        [ 0.0065,  0.0274, -0.0327,  ...,  0.0053,  0.0243,  0.0175],\n",
      "        [-0.0229, -0.0293,  0.0004,  ..., -0.0110,  0.0073, -0.0074]])\n",
      "layers.0.weight\n",
      "tensor([[ 0.0172, -0.0161, -0.0075,  ...,  0.0059, -0.0047,  0.0017],\n",
      "        [-0.0267, -0.0219, -0.0302,  ..., -0.0029,  0.0012, -0.0163],\n",
      "        [ 0.0275, -0.0093, -0.0333,  ..., -0.0138,  0.0055, -0.0328],\n",
      "        ...,\n",
      "        [-0.0015, -0.0159, -0.0231,  ..., -0.0109,  0.0195, -0.0093],\n",
      "        [ 0.0065,  0.0274, -0.0327,  ...,  0.0053,  0.0243,  0.0175],\n",
      "        [-0.0229, -0.0293,  0.0004,  ..., -0.0110,  0.0073, -0.0074]])\n"
     ]
    }
   ],
   "source": [
    "w = 'layers.0.weight'\n",
    "w1 = w.split('.')\n",
    "name = 'fc'+str(int(w1[1])+1)+'.'+w1[2]\n",
    "print(name)\n",
    "print(valen_weights[name])\n",
    "print(w)\n",
    "print(mlp_feature.state_dict()[w])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "z, w = Weak.generate_weak(train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "Data.include_weak(Weak.z)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "trainloader, testloader = Data.get_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 0.9358\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.9358, dtype=torch.float64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(mlp_feature,testloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: Train Loss: nan, Train Acc: 0.1025, Test Acc: 0.0980\n",
      "Epoch 2/100: Train Loss: nan, Train Acc: 0.0987, Test Acc: 0.0980\n",
      "Epoch 3/100: Train Loss: nan, Train Acc: 0.0987, Test Acc: 0.0980\n",
      "Epoch 4/100: Train Loss: nan, Train Acc: 0.0987, Test Acc: 0.0980\n",
      "Epoch 5/100: Train Loss: nan, Train Acc: 0.0987, Test Acc: 0.0980\n",
      "Train loss has not improved in 5 epochs. Stopping early...\n"
     ]
    }
   ],
   "source": [
    "#mlp = MLP(Data.num_features,[Data.num_features,Data.num_features,Data.num_features],Data.num_classes,dropout_p=0.3)\n",
    "#optimizer = torch.optim.Adam(mlp_feature.parameters(), lr=0.01)\n",
    "optimizer = torch.optim.SGD(mlp_feature.parameters(), lr=1e-2, weight_decay=1e-4,momentum=0.9,nesterov=True )\n",
    "loss_fn = EMLoss(Weak.M)\n",
    "\n",
    "mlp_feature,results = ES_train_and_evaluate(mlp_feature,trainloader,testloader,optimizer,loss_fn,num_epochs=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
