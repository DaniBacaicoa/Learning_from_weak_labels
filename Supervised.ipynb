{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Quick example of Supervised\n",
    "## with CE and using the Moore Penrose inverse as the Virtual Label matrix\n",
    "This example tries to show the usage of the classes and methods\n",
    "proposed here to show classification with weakly labeled datasets.\n",
    "In this case we use the **CE** loss."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Importing general libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# Importing specific classes and functions\n",
    "from utils.weakener import Weakener\n",
    "\n",
    "#Importing drawing tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#importing dataloaders\n",
    "from datasets.openml_datasets import OpenML_Dataset\n",
    "from datasets.torch_datasets import Torch_Dataset\n",
    "from models.model import MLP\n",
    "from utils.trainig_testing import train_model,evaluate_model,train_and_evaluate\n",
    "from utils.losses import EMLoss, CELoss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# DS stores the dataset and its related attributes\n",
    "DS = Torch_Dataset('mnist')\n",
    "train_x, train_y, test_x, test_y = DS.get_data()\n",
    "# WL stores pocesses relative to the Weakening process\n",
    "WL = Weakener(DS.num_classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "{0: '1000000000', 1: '0100000000', 2: '0010000000', 3: '0001000000', 4: '0000100000', 5: '0000010000', 6: '0000001000', 7: '0000000100', 8: '0000000010', 9: '0000000001'}\n"
     ]
    }
   ],
   "source": [
    "# Generation of the mixing matrix according to the model\n",
    "#  we've chosen.\n",
    "WL.generate_M(model_class='supervised')\n",
    "print(WL.M)\n",
    "print(WL.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# We generate the weak labels (this step is optional as WL.virtual_labels(train_y) can do it)\n",
    "z, w = WL.generate_weak(train_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "z is the numerical encodig of the weak label while w is a one-hot\n",
    "representation of that variable. z also encodes the row of the M matrix\n",
    "for that given weak label.\n",
    "\n",
    "Let's consider the example of partial label learning for the iris dataset.\n",
    "labels are encoded as ```{0: '011', 1: '101', 2: '110', 3: '111'}```\n",
    "so having an isntance with `z=3` means `w=[1,1,1]`, i.e., the weak label contains every label."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We generate the weak labels (this step is optional as WL.virtual_labels(train_y) can do it)\n",
    "WL.virtual_matrix(convex=True)\n",
    "#And we generate the virtual labels\n",
    "WL.virtual_labels(train_y)\n",
    "WL.v[:10,:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "#We need to include this Weak Labels into the dataset,\n",
    "# we need to include w to mantain the coherence. z will only be used\n",
    "# in the loss for the EM\n",
    "DS.include_weak(WL.v)\n",
    "# Once we have our dataset with all the labels we need we can create the dataloaders.\n",
    "trainloader, testloader = DS.get_dataloader()\n",
    "\n",
    "print(len(testloader.dataset))\n",
    "print(len(trainloader.dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we have a trainloader containing (X,v,y) and a testloader containig (X,y)\n",
    "so we can just establish our model and train it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CELoss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Define the optimizer and loss function\u001B[39;00m\n\u001B[0;32m      6\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(mlp\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m loss_fn \u001B[38;5;241m=\u001B[39m \u001B[43mCELoss\u001B[49m()\n\u001B[0;32m      9\u001B[0m train_losses,train_accs\u001B[38;5;241m=\u001B[39mtrain_model(mlp,trainloader,optimizer,\n\u001B[0;32m     10\u001B[0m                                     loss_fn,num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Print the final training loss and accuracy\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'CELoss' is not defined"
     ]
    }
   ],
   "source": [
    "# Create an instance of the MLP class\n",
    "mlp = MLP(input_size=DS.num_features, hidden_sizes=[20],\n",
    "          output_size=DS.num_classes, dropout_p=0.5)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_fn = CELoss()\n",
    "\n",
    "train_losses,train_accs=train_model(mlp,trainloader,optimizer,\n",
    "                                    loss_fn,num_epochs=10)\n",
    "\n",
    "# Print the final training loss and accuracy\n",
    "print('Final Training Loss: {:.4f}'.format(train_losses[-1]))\n",
    "print('Final Training Accuracy: {:.4f}'.format(train_accs[-1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0].plot(train_losses)\n",
    "axis[0].set_title(\"Train_loss\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[1].plot(train_accs)\n",
    "axis[1].set_title(\"Train_accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an instance of the MLP class\n",
    "mlp = MLP(input_size=DS.num_features, hidden_sizes=[20],\n",
    "          output_size=DS.num_classes, dropout_p=0.5)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_fn = CELoss()\n",
    "\n",
    "# Train and evaluate the MLP on the training data, test data, and get the results\n",
    "mlp, results = train_and_evaluate(mlp, trainloader, testloader,\n",
    "                                  optimizer, loss_fn, num_epochs=10)\n",
    "\n",
    "# Print the results\n",
    "print('Train Loss:', results['train_loss'][-1])\n",
    "print('Train Accuracy:', results['train_acc'][-1])\n",
    "print('Test Accuracy:', results['test_acc'][-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(1, 2)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0].plot(results['train_loss'])\n",
    "axis[0].set_title(\"Train_loss\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[1].plot(results['train_acc'])\n",
    "axis[1].plot(results['test_acc'])\n",
    "axis[1].set_title(\"Accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}