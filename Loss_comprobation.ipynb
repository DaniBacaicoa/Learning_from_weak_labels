{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.losses as loss\n",
    "import datasets.datasets as dtset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danibacaicoa\\vscode_projects\\Learning_from_weak_labels\\datasets\\datasets.py:86: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  data = openml.datasets.get_dataset(openml_ids[self.dataset])\n"
     ]
    }
   ],
   "source": [
    "Data = dtset.OpenML_Dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([105, 4])\n"
     ]
    }
   ],
   "source": [
    "train_X,train_y,test_X,test_y =  Data.get_data()\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.6000, 2.8000, 4.9000, 2.0000],\n",
      "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
      "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
      "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
      "        [4.4000, 2.9000, 1.4000, 0.2000]])\n",
      "tensor([[0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(train_X[:5,:])\n",
    "print(train_y[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.2267,  1.0525, -3.7203],\n",
      "        [-2.6616,  0.9027, -3.6360],\n",
      "        [-3.6354,  1.2185, -4.0475],\n",
      "        [-3.4079,  1.1829, -4.1272],\n",
      "        [-1.8166,  0.5079, -2.7220],\n",
      "        [-2.3070,  0.7371, -3.2525],\n",
      "        [-1.7406,  0.4724, -2.6398],\n",
      "        [-2.3115,  0.7392, -3.2573],\n",
      "        [-3.9081,  1.3274, -4.2570],\n",
      "        [-1.9479,  0.5693, -2.8641],\n",
      "        [-1.9168,  0.5547, -2.8304],\n",
      "        [-2.2038,  0.6889, -3.1409],\n",
      "        [-3.4256,  1.1274, -3.8524],\n",
      "        [-2.1465,  0.6621, -3.0789],\n",
      "        [-3.5956,  1.2502, -4.2362],\n",
      "        [-4.3203,  1.5347, -4.7703],\n",
      "        [-3.7764,  1.2827, -4.1919],\n",
      "        [-2.3136,  0.7401, -3.2596],\n",
      "        [-2.0953,  0.6382, -3.0235],\n",
      "        [-2.2802,  0.7245, -3.2235],\n",
      "        [-3.9893,  1.3681, -4.3573],\n",
      "        [-2.5615,  0.8560, -3.5278],\n",
      "        [-2.6515,  0.8752, -3.5197],\n",
      "        [-1.9159,  0.5543, -2.8294],\n",
      "        [-2.8148,  0.9531, -3.7037],\n",
      "        [-3.0096,  1.0555, -3.9668],\n",
      "        [-3.5865,  1.2296, -4.1509],\n",
      "        [-3.3228,  1.1903, -4.2526],\n",
      "        [-2.1746,  0.6752, -3.1093],\n",
      "        [-4.4413,  1.5521, -4.7209],\n",
      "        [-1.9717,  0.5804, -2.8898],\n",
      "        [-2.8395,  0.9615, -3.7159],\n",
      "        [-2.3219,  0.7440, -3.2686],\n",
      "        [-3.0640,  1.0421, -3.8471],\n",
      "        [-3.7718,  1.2628, -4.1053],\n",
      "        [-2.5724,  0.8611, -3.5396],\n",
      "        [-2.1994,  0.6868, -3.1361],\n",
      "        [-2.1808,  0.6781, -3.1160],\n",
      "        [-3.2774,  1.1354, -4.0481],\n",
      "        [-2.3233,  0.7447, -3.2701],\n",
      "        [-2.2389,  0.7053, -3.1789],\n",
      "        [-3.0847,  1.0492, -3.8574],\n",
      "        [-3.2721,  1.1074, -3.9249],\n",
      "        [-2.6652,  0.8762, -3.5097],\n",
      "        [-2.6652,  0.9045, -3.6400],\n",
      "        [-1.9796,  0.5841, -2.8983],\n",
      "        [-2.8726,  0.9723, -3.7304],\n",
      "        [-3.2556,  1.1414, -4.0992],\n",
      "        [-2.0491,  0.6166, -2.9735],\n",
      "        [-3.3831,  1.1945, -4.2072],\n",
      "        [-3.4567,  1.1616, -3.9764],\n",
      "        [-2.2958,  0.7318, -3.2403],\n",
      "        [-3.2389,  1.0966, -3.9105],\n",
      "        [-3.1189,  1.0673, -3.9043],\n",
      "        [-3.2212,  1.0445, -3.6893],\n",
      "        [-2.6902,  0.8940, -3.5652],\n",
      "        [-3.9242,  1.3541, -4.3626],\n",
      "        [-2.6320,  0.8857, -3.5892],\n",
      "        [-2.7199,  0.9300, -3.6991],\n",
      "        [-2.9540,  1.0117, -3.8248],\n",
      "        [-3.9294,  1.3033, -4.1228],\n",
      "        [-2.0129,  0.5996, -2.9343],\n",
      "        [-2.0944,  0.6377, -3.0225],\n",
      "        [-2.1608,  0.6688, -3.0944],\n",
      "        [-3.1535,  1.0949, -3.9944],\n",
      "        [-3.7781,  1.2690, -4.1272],\n",
      "        [-2.1964,  0.6854, -3.1329],\n",
      "        [-3.2727,  1.0865, -3.8277],\n",
      "        [-3.6252,  1.2094, -4.0161],\n",
      "        [-2.8656,  0.8981, -3.3960],\n",
      "        [-3.6703,  1.2345, -4.0835],\n",
      "        [-1.9216,  0.5570, -2.8355],\n",
      "        [-2.7587,  0.9406, -3.7063],\n",
      "        [-3.6213,  1.2268, -4.1006],\n",
      "        [-1.9796,  0.5841, -2.8983],\n",
      "        [-2.4492,  0.8035, -3.4063],\n",
      "        [-3.7687,  1.3091, -4.3219],\n",
      "        [-2.9988,  0.9887, -3.6704],\n",
      "        [-2.1368,  0.6576, -3.0684],\n",
      "        [-3.8705,  1.3158, -4.2440],\n",
      "        [-1.9865,  0.5873, -2.9058],\n",
      "        [-3.2495,  1.0945, -3.8895],\n",
      "        [-3.1125,  1.1002, -4.0626],\n",
      "        [-4.1526,  1.4357, -4.4939],\n",
      "        [-3.5796,  1.1948, -3.9977],\n",
      "        [-3.1530,  1.1058, -4.0450],\n",
      "        [-4.0730,  1.4225, -4.5184],\n",
      "        [-3.1825,  1.0750, -3.8715],\n",
      "        [-3.5077,  1.2041, -4.1181],\n",
      "        [-3.3174,  1.1229, -3.9474],\n",
      "        [-2.2479,  0.7095, -3.1886],\n",
      "        [-3.2741,  1.1029, -3.9017],\n",
      "        [-1.7064,  0.4564, -2.6028],\n",
      "        [-1.9356,  0.5635, -2.8507],\n",
      "        [-3.2781,  1.1539, -4.1329],\n",
      "        [-2.8380,  0.9852, -3.8269],\n",
      "        [-3.8454,  1.3183, -4.2824],\n",
      "        [-1.8154,  0.5074, -2.7207],\n",
      "        [-3.1206,  1.0250, -3.7075],\n",
      "        [-3.6819,  1.2604, -4.1906],\n",
      "        [-3.5940,  1.2143, -4.0724],\n",
      "        [-2.8198,  0.9430, -3.6517],\n",
      "        [-3.6422,  1.2139, -4.0188],\n",
      "        [-2.9178,  0.9982, -3.8012],\n",
      "        [-3.1459,  1.1201, -4.1185]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the MLP class\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super().__init__()\n",
    "    # Define layers\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    self.softmax = nn.Softmax(dim=1)  # For classification tasks\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Forward pass through the layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "model = MLP(4, 2, 3)\n",
    "\n",
    "prediction = model(train_X)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader =  Data.get_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = loss.GumbelLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gumbel_softmax' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\Learning_from_weak_labels\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\Learning_from_weak_labels\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danibacaicoa\\vscode_projects\\Learning_from_weak_labels\\utils\\losses.py:128\u001b[0m, in \u001b[0;36mGumbelLoss.forward\u001b[1;34m(self, inputs, targets)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, targets):\n\u001b[0;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    Gumbel Softmax loss function\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    Tensor of Gumbel Softmax loss value.\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mgumbel_softmax\u001b[49m(inputs)\n\u001b[0;32m    129\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean(targets \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(y \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps))\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m L\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gumbel_softmax' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop (with improvements):\n",
    "for epoch in range(101):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # Get the inputs; forward pass:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(running_loss)\n",
    "    \n",
    "print('Finished training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([2.2311, 1.2917, 1.1168, 3.3529, 2.8421, 1.2917, 2.2608, 1.2917, 3.9848,\n",
      "        1.2917, 1.2917, 1.2917, 2.4093, 2.0132, 0.9108, 1.2597, 1.2017, 1.2917,\n",
      "        1.2917, 1.2917, 2.2239, 1.2917, 0.7512, 1.2917, 1.2170, 2.2608, 1.2917,\n",
      "        2.8851, 1.2917, 3.3500, 1.2917, 1.2917, 1.2917, 2.4532, 1.1275, 1.2917,\n",
      "        2.6637, 2.1153, 1.2917, 0.9961, 1.0828, 1.7866, 1.1821, 1.2917, 0.9425]),\n",
      "indices=tensor([2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 0, 1, 0,\n",
      "        1, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 1]))\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_dataloader:\n",
    "    outputs = model(images)\n",
    "    outputs\n",
    "    print(torch.max(outputs.data, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 0, 1, 0,\n",
      "        1, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 1])\n",
      "tensor([2, 0, 1, 2, 2, 0, 2, 0, 2, 0, 0, 0, 2, 2, 1, 1, 1, 0, 0, 0, 2, 0, 1, 0,\n",
      "        1, 2, 0, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 2, 1, 0, 1])\n",
      "Accuracy of the network on the test images: 100 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model:\n",
    "total_correct = 0\n",
    "total_data = 0\n",
    "with torch.no_grad():  # Disable gradient calculation for testing\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get the predicted class label\n",
    "        print(predicted)\n",
    "        print(torch.max(labels,1)[1])\n",
    "        total_correct += (predicted == torch.max(labels,1)[1]).sum().item()  # Count correct predictions\n",
    "        total_data += labels.size(0)\n",
    "\n",
    "accuracy = total_correct / total_data\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
