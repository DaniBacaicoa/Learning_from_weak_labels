{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example of Weak Label Learning with warm up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "from datasets import openml_datasets,torch_datasets\n",
    "from utils import weakener, losses, trainig_testing\n",
    "from models import general_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DS = openml_datasets.OpenML_Dataset('iris')\n",
    "train_x, train_y, test_x, test_y = DS.get_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "tensor(3, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(DS.num_features)\n",
    "print(DS.num_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Weak = weakener.Weakener(DS.num_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'c', 'generate_M', 'generate_weak', 'generate_wl_priors', 'label_matrix', 'pll_weights', 'virtual_labels', 'virtual_matrix', 'w', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(dir(Weak))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'iris', 'tr_size': 0.7, 'weak_labels': None, 'batch_size': 64, 'shuffle': True, 'splitting_seed': 47, 'num_classes': tensor(3, dtype=torch.int32), 'train_dataset': <torch.utils.data.dataset.TensorDataset object at 0x0000021B8B179D60>, 'test_dataset': <torch.utils.data.dataset.TensorDataset object at 0x0000021B8B179CD0>, 'train_num_samples': 105, 'test_num_samples': 45, 'num_features': 4}\n"
     ]
    }
   ],
   "source": [
    "print(DS.__dict__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "Weak.generate_M(model_class='pll')\n",
    "z, w  = Weak.generate_weak(train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c': tensor(3, dtype=torch.int32), 'M': array([[0.   , 0.375, 0.375],\n",
      "       [0.375, 0.   , 0.375],\n",
      "       [0.375, 0.375, 0.   ],\n",
      "       [0.25 , 0.25 , 0.25 ]]), 'z': tensor([0, 2, 3, 2, 3, 2, 2, 2, 1, 2, 3, 2, 0, 1, 1, 1, 0, 2, 3, 2, 1, 3, 3, 2,\n",
      "        0, 2, 1, 3, 2, 1, 1, 2, 2, 0, 1, 0, 3, 2, 0, 2, 2, 0, 1, 0, 2, 1, 0, 3,\n",
      "        2, 2, 0, 0, 1, 2, 1, 0, 1, 2, 0, 0, 3, 1, 3, 2, 3, 1, 1, 2, 3, 1, 3, 3,\n",
      "        2, 1, 1, 1, 3, 3, 1, 1, 2, 0, 2, 3, 3, 3, 0, 2, 0, 3, 3, 2, 3, 2, 2, 3,\n",
      "        1, 2, 1, 0, 3, 0, 1, 3, 3], dtype=torch.int32), 'w': tensor([[0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 0., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 0., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64), 'pll_p': 0.5, 'Z': array([[0, 1, 1],\n",
      "       [1, 0, 1],\n",
      "       [1, 1, 0],\n",
      "       [1, 1, 1]]), 'labels': {0: '011', 1: '101', 2: '110', 3: '111'}}\n"
     ]
    }
   ],
   "source": [
    "print(Weak.__dict__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#As we are first making a warm up, we will include in the dataset w\n",
    "DS.include_weak(Weak.w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "trainloader_wu, testloader_wu = DS.get_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Begin the training process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#This is the mlp used by Valen for [mnist,kmnist,fmnist] with random partialization (aka instance independet corruption)\n",
    "mlp = general_model.MLP(DS.num_features, [DS.num_features, DS.num_features, DS.num_features], DS.num_classes, dropout_p = 0.0, bn = False, seed = 10,\n",
    "                        layer_init = lambda x: torch.nn.init.kaiming_uniform_(x, a=math.sqrt(5)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 0.0221, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 2/10: Train Loss: 0.0206, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 3/10: Train Loss: 0.0205, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 4/10: Train Loss: 0.0203, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 5/10: Train Loss: 0.0204, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 6/10: Train Loss: 0.0205, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 7/10: Train Loss: 0.0205, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 8/10: Train Loss: 0.0207, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 9/10: Train Loss: 0.0206, Train Acc: 0.3714, Test Acc: 0.2444\n",
      "Epoch 10/10: Train Loss: 0.0205, Train Acc: 0.3714, Test Acc: 0.2444\n"
     ]
    }
   ],
   "source": [
    "#optim  = torch.optim.SGD(mlp.parameters(), lr = 1e-2, weight_decay = 1e-4, momentum = 0.9)\n",
    "optim_wu  = torch.optim.SGD(mlp.parameters(), lr = 1e-2, weight_decay = 1e-4, momentum = 0.9)\n",
    "loss_fn_wu = losses.PartialLoss(Weak.w)\n",
    "\n",
    "mlp, results_wu = trainig_testing.train_and_evaluate(mlp, trainloader_wu, testloader_wu, optim_wu, loss_fn_wu, num_epochs = 10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "Weak.virtual_labels(train_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "DS.include_weak(Weak.v)\n",
    "trainloader, testloader = DS.get_dataloader()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/490: Train Loss: 1.1118, Train Acc: 0.3714, Test Acc: 0.4222\n",
      "Epoch 2/490: Train Loss: 1.0397, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 3/490: Train Loss: 1.0378, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 4/490: Train Loss: 1.0767, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 5/490: Train Loss: 1.0782, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 6/490: Train Loss: 1.0384, Train Acc: 0.2952, Test Acc: 0.2444\n",
      "Epoch 7/490: Train Loss: 1.0558, Train Acc: 0.3714, Test Acc: 0.4222\n",
      "Epoch 8/490: Train Loss: 1.0695, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 9/490: Train Loss: 1.0308, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 10/490: Train Loss: 1.0347, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 11/490: Train Loss: 1.0316, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 12/490: Train Loss: 1.0259, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 13/490: Train Loss: 1.0329, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 14/490: Train Loss: 1.0330, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 15/490: Train Loss: 1.0490, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 16/490: Train Loss: 1.0385, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 17/490: Train Loss: 1.0312, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 18/490: Train Loss: 1.0642, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 19/490: Train Loss: 1.0385, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 20/490: Train Loss: 1.0440, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 21/490: Train Loss: 1.0440, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 22/490: Train Loss: 1.0353, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 23/490: Train Loss: 1.0329, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 24/490: Train Loss: 1.0351, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 25/490: Train Loss: 1.0318, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 26/490: Train Loss: 1.0441, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 27/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 28/490: Train Loss: 1.0265, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 29/490: Train Loss: 1.0268, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 30/490: Train Loss: 1.0300, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 31/490: Train Loss: 1.0547, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 32/490: Train Loss: 1.0284, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 33/490: Train Loss: 1.0434, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 34/490: Train Loss: 1.0342, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 35/490: Train Loss: 1.0273, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 36/490: Train Loss: 1.0299, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 37/490: Train Loss: 1.0375, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 38/490: Train Loss: 1.0350, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 39/490: Train Loss: 1.0394, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 40/490: Train Loss: 1.0410, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 41/490: Train Loss: 1.0337, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 42/490: Train Loss: 1.0597, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 43/490: Train Loss: 1.0432, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 44/490: Train Loss: 1.0312, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 45/490: Train Loss: 1.0293, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 46/490: Train Loss: 1.0313, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 47/490: Train Loss: 1.0328, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 48/490: Train Loss: 1.0397, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 49/490: Train Loss: 1.0528, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 50/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 51/490: Train Loss: 1.0297, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 52/490: Train Loss: 1.0288, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 53/490: Train Loss: 1.0278, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 54/490: Train Loss: 1.0274, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 55/490: Train Loss: 1.0270, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 56/490: Train Loss: 1.0354, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 57/490: Train Loss: 1.0319, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 58/490: Train Loss: 1.0297, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 59/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 60/490: Train Loss: 1.0318, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 61/490: Train Loss: 1.0334, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 62/490: Train Loss: 1.0362, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 63/490: Train Loss: 1.0281, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 64/490: Train Loss: 1.0412, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 65/490: Train Loss: 1.0306, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 66/490: Train Loss: 1.0273, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 67/490: Train Loss: 1.0559, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 68/490: Train Loss: 1.0362, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 69/490: Train Loss: 1.0303, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 70/490: Train Loss: 1.0641, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 71/490: Train Loss: 1.0491, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 72/490: Train Loss: 1.0473, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 73/490: Train Loss: 1.0324, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 74/490: Train Loss: 1.0283, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 75/490: Train Loss: 1.0492, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 76/490: Train Loss: 1.0348, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 77/490: Train Loss: 1.0363, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 78/490: Train Loss: 1.0282, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 79/490: Train Loss: 1.0285, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 80/490: Train Loss: 1.0375, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 81/490: Train Loss: 1.0430, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 82/490: Train Loss: 1.0321, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 83/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 84/490: Train Loss: 1.0288, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 85/490: Train Loss: 1.0314, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 86/490: Train Loss: 1.0402, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 87/490: Train Loss: 1.0308, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 88/490: Train Loss: 1.0420, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 89/490: Train Loss: 1.0371, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 90/490: Train Loss: 1.0340, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 91/490: Train Loss: 1.0358, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 92/490: Train Loss: 1.0732, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 93/490: Train Loss: 1.0337, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 94/490: Train Loss: 1.0287, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 95/490: Train Loss: 1.0273, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 96/490: Train Loss: 1.0341, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 97/490: Train Loss: 1.0395, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 98/490: Train Loss: 1.0302, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 99/490: Train Loss: 1.0403, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 100/490: Train Loss: 1.0381, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 101/490: Train Loss: 1.0316, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 102/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 103/490: Train Loss: 1.0388, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 104/490: Train Loss: 1.0327, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 105/490: Train Loss: 1.0271, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 106/490: Train Loss: 1.0393, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 107/490: Train Loss: 1.0338, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 108/490: Train Loss: 1.0306, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 109/490: Train Loss: 1.0380, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 110/490: Train Loss: 1.0392, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 111/490: Train Loss: 1.0357, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 112/490: Train Loss: 1.0308, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 113/490: Train Loss: 1.0267, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 114/490: Train Loss: 1.0340, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 115/490: Train Loss: 1.0341, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 116/490: Train Loss: 1.0341, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 117/490: Train Loss: 1.0327, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 118/490: Train Loss: 1.0426, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 119/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 120/490: Train Loss: 1.0518, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 121/490: Train Loss: 1.0389, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 122/490: Train Loss: 1.0391, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 123/490: Train Loss: 1.0394, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 124/490: Train Loss: 1.0362, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 125/490: Train Loss: 1.0304, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 126/490: Train Loss: 1.0369, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 127/490: Train Loss: 1.0354, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 128/490: Train Loss: 1.0324, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 129/490: Train Loss: 1.0399, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 130/490: Train Loss: 1.0359, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 131/490: Train Loss: 1.0283, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 132/490: Train Loss: 1.0377, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 133/490: Train Loss: 1.0291, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 134/490: Train Loss: 1.0337, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 135/490: Train Loss: 1.0326, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 136/490: Train Loss: 1.0441, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 137/490: Train Loss: 1.0527, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 138/490: Train Loss: 1.0904, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 139/490: Train Loss: 1.0354, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 140/490: Train Loss: 1.0267, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 141/490: Train Loss: 1.0316, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 142/490: Train Loss: 1.0404, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 143/490: Train Loss: 1.0331, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 144/490: Train Loss: 1.0343, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 145/490: Train Loss: 1.0287, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 146/490: Train Loss: 1.0289, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 147/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 148/490: Train Loss: 1.0312, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 149/490: Train Loss: 1.0293, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 150/490: Train Loss: 1.0316, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 151/490: Train Loss: 1.0347, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 152/490: Train Loss: 1.0270, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 153/490: Train Loss: 1.0359, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 154/490: Train Loss: 1.0309, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 155/490: Train Loss: 1.0358, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 156/490: Train Loss: 1.0271, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 157/490: Train Loss: 1.0298, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 158/490: Train Loss: 1.0504, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 159/490: Train Loss: 1.0387, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 160/490: Train Loss: 1.0487, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 161/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 162/490: Train Loss: 1.0266, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 163/490: Train Loss: 1.0404, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 164/490: Train Loss: 1.0378, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 165/490: Train Loss: 1.0671, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 166/490: Train Loss: 1.0473, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 167/490: Train Loss: 1.0512, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 168/490: Train Loss: 1.0357, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 169/490: Train Loss: 1.0363, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 170/490: Train Loss: 1.0388, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 171/490: Train Loss: 1.0292, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 172/490: Train Loss: 1.0296, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 173/490: Train Loss: 1.0280, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 174/490: Train Loss: 1.0433, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 175/490: Train Loss: 1.0340, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 176/490: Train Loss: 1.0354, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 177/490: Train Loss: 1.0279, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 178/490: Train Loss: 1.0282, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 179/490: Train Loss: 1.0350, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 180/490: Train Loss: 1.0339, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 181/490: Train Loss: 1.0326, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 182/490: Train Loss: 1.0442, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 183/490: Train Loss: 1.0259, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 184/490: Train Loss: 1.0277, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 185/490: Train Loss: 1.0287, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 186/490: Train Loss: 1.0312, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 187/490: Train Loss: 1.0398, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 188/490: Train Loss: 1.0391, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 189/490: Train Loss: 1.0328, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 190/490: Train Loss: 1.0396, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 191/490: Train Loss: 1.0339, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 192/490: Train Loss: 1.0316, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 193/490: Train Loss: 1.0336, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 194/490: Train Loss: 1.0292, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 195/490: Train Loss: 1.0442, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 196/490: Train Loss: 1.0297, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 197/490: Train Loss: 1.0299, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 198/490: Train Loss: 1.0345, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 199/490: Train Loss: 1.0609, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 200/490: Train Loss: 1.0457, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 201/490: Train Loss: 1.0511, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 202/490: Train Loss: 1.0491, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 203/490: Train Loss: 1.0357, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 204/490: Train Loss: 1.0365, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 205/490: Train Loss: 1.0371, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 206/490: Train Loss: 1.0372, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 207/490: Train Loss: 1.0334, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 208/490: Train Loss: 1.0461, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 209/490: Train Loss: 1.0257, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 210/490: Train Loss: 1.0282, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 211/490: Train Loss: 1.0402, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 212/490: Train Loss: 1.0416, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 213/490: Train Loss: 1.0395, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 214/490: Train Loss: 1.0302, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 215/490: Train Loss: 1.0547, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 216/490: Train Loss: 1.0574, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 217/490: Train Loss: 1.0298, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 218/490: Train Loss: 1.0372, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 219/490: Train Loss: 1.0424, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 220/490: Train Loss: 1.0396, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 221/490: Train Loss: 1.0360, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 222/490: Train Loss: 1.0387, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 223/490: Train Loss: 1.0497, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 224/490: Train Loss: 1.0300, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 225/490: Train Loss: 1.0394, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 226/490: Train Loss: 1.0326, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 227/490: Train Loss: 1.0347, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 228/490: Train Loss: 1.0399, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 229/490: Train Loss: 1.0459, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 230/490: Train Loss: 1.0498, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 231/490: Train Loss: 1.0376, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 232/490: Train Loss: 1.0489, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 233/490: Train Loss: 1.0391, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 234/490: Train Loss: 1.0352, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 235/490: Train Loss: 1.0341, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 236/490: Train Loss: 1.0484, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 237/490: Train Loss: 1.0338, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 238/490: Train Loss: 1.0505, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 239/490: Train Loss: 1.0278, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 240/490: Train Loss: 1.0312, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 241/490: Train Loss: 1.0374, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 242/490: Train Loss: 1.0378, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 243/490: Train Loss: 1.0281, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 244/490: Train Loss: 1.0468, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 245/490: Train Loss: 1.0416, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 246/490: Train Loss: 1.0378, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 247/490: Train Loss: 1.0435, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 248/490: Train Loss: 1.0338, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 249/490: Train Loss: 1.0301, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 250/490: Train Loss: 1.0521, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 251/490: Train Loss: 1.0624, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 252/490: Train Loss: 1.0304, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 253/490: Train Loss: 1.0436, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 254/490: Train Loss: 1.0481, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 255/490: Train Loss: 1.0583, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 256/490: Train Loss: 1.0417, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 257/490: Train Loss: 1.0499, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 258/490: Train Loss: 1.0419, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 259/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 260/490: Train Loss: 1.0296, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 261/490: Train Loss: 1.0335, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 262/490: Train Loss: 1.0557, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 263/490: Train Loss: 1.0323, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 264/490: Train Loss: 1.0331, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 265/490: Train Loss: 1.0373, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 266/490: Train Loss: 1.0336, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 267/490: Train Loss: 1.0592, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 268/490: Train Loss: 1.0306, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 269/490: Train Loss: 1.0353, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 270/490: Train Loss: 1.0285, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 271/490: Train Loss: 1.0397, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 272/490: Train Loss: 1.0427, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 273/490: Train Loss: 1.0353, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 274/490: Train Loss: 1.0382, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 275/490: Train Loss: 1.0439, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 276/490: Train Loss: 1.0336, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 277/490: Train Loss: 1.0285, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 278/490: Train Loss: 1.0366, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 279/490: Train Loss: 1.0445, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 280/490: Train Loss: 1.0302, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 281/490: Train Loss: 1.0366, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 282/490: Train Loss: 1.0294, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 283/490: Train Loss: 1.0316, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 284/490: Train Loss: 1.0295, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 285/490: Train Loss: 1.0319, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 286/490: Train Loss: 1.0369, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 287/490: Train Loss: 1.0361, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 288/490: Train Loss: 1.0609, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 289/490: Train Loss: 1.0296, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 290/490: Train Loss: 1.0340, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 291/490: Train Loss: 1.0371, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 292/490: Train Loss: 1.0298, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 293/490: Train Loss: 1.0278, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 294/490: Train Loss: 1.0313, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 295/490: Train Loss: 1.0333, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 296/490: Train Loss: 1.0728, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 297/490: Train Loss: 1.0473, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 298/490: Train Loss: 1.0320, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 299/490: Train Loss: 1.0264, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 300/490: Train Loss: 1.0291, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 301/490: Train Loss: 1.0523, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 302/490: Train Loss: 1.0301, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 303/490: Train Loss: 1.0284, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 304/490: Train Loss: 1.0350, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 305/490: Train Loss: 1.0292, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 306/490: Train Loss: 1.0295, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 307/490: Train Loss: 1.0315, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 308/490: Train Loss: 1.0274, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 309/490: Train Loss: 1.0519, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 310/490: Train Loss: 1.0387, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 311/490: Train Loss: 1.0391, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 312/490: Train Loss: 1.0422, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 313/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 314/490: Train Loss: 1.0297, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 315/490: Train Loss: 1.0404, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 316/490: Train Loss: 1.0400, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 317/490: Train Loss: 1.0339, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 318/490: Train Loss: 1.0679, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 319/490: Train Loss: 1.0361, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 320/490: Train Loss: 1.0269, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 321/490: Train Loss: 1.0356, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 322/490: Train Loss: 1.0353, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 323/490: Train Loss: 1.0361, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 324/490: Train Loss: 1.0359, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 325/490: Train Loss: 1.0261, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 326/490: Train Loss: 1.0361, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 327/490: Train Loss: 1.0389, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 328/490: Train Loss: 1.0301, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 329/490: Train Loss: 1.0339, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 330/490: Train Loss: 1.0457, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 331/490: Train Loss: 1.0348, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 332/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 333/490: Train Loss: 1.0557, Train Acc: 0.2952, Test Acc: 0.2444\n",
      "Epoch 334/490: Train Loss: 1.0492, Train Acc: 0.3333, Test Acc: 0.4222\n",
      "Epoch 335/490: Train Loss: 1.0406, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 336/490: Train Loss: 1.0359, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 337/490: Train Loss: 1.0379, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 338/490: Train Loss: 1.0352, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 339/490: Train Loss: 1.0659, Train Acc: 0.2952, Test Acc: 0.2444\n",
      "Epoch 340/490: Train Loss: 1.0404, Train Acc: 0.2857, Test Acc: 0.4222\n",
      "Epoch 341/490: Train Loss: 1.0421, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 342/490: Train Loss: 1.0327, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 343/490: Train Loss: 1.0417, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 344/490: Train Loss: 1.0567, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 345/490: Train Loss: 1.1023, Train Acc: 0.3048, Test Acc: 0.2444\n",
      "Epoch 346/490: Train Loss: 1.0596, Train Acc: 0.3143, Test Acc: 0.4222\n",
      "Epoch 347/490: Train Loss: 1.0398, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 348/490: Train Loss: 1.0549, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 349/490: Train Loss: 1.0620, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 350/490: Train Loss: 1.0260, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 351/490: Train Loss: 1.0460, Train Acc: 0.2667, Test Acc: 0.4222\n",
      "Epoch 352/490: Train Loss: 1.0499, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 353/490: Train Loss: 1.0313, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 354/490: Train Loss: 1.0422, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 355/490: Train Loss: 1.0421, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 356/490: Train Loss: 1.0362, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 357/490: Train Loss: 1.0325, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 358/490: Train Loss: 1.0476, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 359/490: Train Loss: 1.0444, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 360/490: Train Loss: 1.0552, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 361/490: Train Loss: 1.0328, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 362/490: Train Loss: 1.0479, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 363/490: Train Loss: 1.0392, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 364/490: Train Loss: 1.0527, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 365/490: Train Loss: 1.0275, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 366/490: Train Loss: 1.0432, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 367/490: Train Loss: 1.0389, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 368/490: Train Loss: 1.0499, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 369/490: Train Loss: 1.0305, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 370/490: Train Loss: 1.0294, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 371/490: Train Loss: 1.0262, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 372/490: Train Loss: 1.0349, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 373/490: Train Loss: 1.0432, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 374/490: Train Loss: 1.0377, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 375/490: Train Loss: 1.0376, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 376/490: Train Loss: 1.0415, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 377/490: Train Loss: 1.0420, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 378/490: Train Loss: 1.0301, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 379/490: Train Loss: 1.0643, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 380/490: Train Loss: 1.0411, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 381/490: Train Loss: 1.0386, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 382/490: Train Loss: 1.0252, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 383/490: Train Loss: 1.0369, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 384/490: Train Loss: 1.0444, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 385/490: Train Loss: 1.0307, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 386/490: Train Loss: 1.0351, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 387/490: Train Loss: 1.0339, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 388/490: Train Loss: 1.0699, Train Acc: 0.2762, Test Acc: 0.4222\n",
      "Epoch 389/490: Train Loss: 1.0525, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 390/490: Train Loss: 1.0299, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 391/490: Train Loss: 1.0527, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 392/490: Train Loss: 1.0303, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 393/490: Train Loss: 1.0346, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 394/490: Train Loss: 1.0389, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 395/490: Train Loss: 1.0340, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 396/490: Train Loss: 1.0280, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 397/490: Train Loss: 1.0297, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 398/490: Train Loss: 1.0271, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 399/490: Train Loss: 1.0323, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 400/490: Train Loss: 1.0382, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 401/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 402/490: Train Loss: 1.0299, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 403/490: Train Loss: 1.0309, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 404/490: Train Loss: 1.0420, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 405/490: Train Loss: 1.0309, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 406/490: Train Loss: 1.0420, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 407/490: Train Loss: 1.0382, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 408/490: Train Loss: 1.0295, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 409/490: Train Loss: 1.0304, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 410/490: Train Loss: 1.0506, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 411/490: Train Loss: 1.0311, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 412/490: Train Loss: 1.0582, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 413/490: Train Loss: 1.0309, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 414/490: Train Loss: 1.0338, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 415/490: Train Loss: 1.0403, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 416/490: Train Loss: 1.0448, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 417/490: Train Loss: 1.0317, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 418/490: Train Loss: 1.0294, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 419/490: Train Loss: 1.0300, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 420/490: Train Loss: 1.0423, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 421/490: Train Loss: 1.0331, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 422/490: Train Loss: 1.0459, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 423/490: Train Loss: 1.0408, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 424/490: Train Loss: 1.0479, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 425/490: Train Loss: 1.0282, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 426/490: Train Loss: 1.0415, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 427/490: Train Loss: 1.0295, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 428/490: Train Loss: 1.0358, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 429/490: Train Loss: 1.0365, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 430/490: Train Loss: 1.0618, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 431/490: Train Loss: 1.0331, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 432/490: Train Loss: 1.0318, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 433/490: Train Loss: 1.0366, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 434/490: Train Loss: 1.0299, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 435/490: Train Loss: 1.0304, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 436/490: Train Loss: 1.0331, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 437/490: Train Loss: 1.0273, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 438/490: Train Loss: 1.0309, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 439/490: Train Loss: 1.0411, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 440/490: Train Loss: 1.0345, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 441/490: Train Loss: 1.0466, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 442/490: Train Loss: 1.0410, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 443/490: Train Loss: 1.0447, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 444/490: Train Loss: 1.0314, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 445/490: Train Loss: 1.0313, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 446/490: Train Loss: 1.0392, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 447/490: Train Loss: 1.0321, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 448/490: Train Loss: 1.0297, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 449/490: Train Loss: 1.0289, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 450/490: Train Loss: 1.0728, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 451/490: Train Loss: 1.0337, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 452/490: Train Loss: 1.0606, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 453/490: Train Loss: 1.0396, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 454/490: Train Loss: 1.0288, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 455/490: Train Loss: 1.0295, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 456/490: Train Loss: 1.0532, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 457/490: Train Loss: 1.0400, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 458/490: Train Loss: 1.0433, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 459/490: Train Loss: 1.0289, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 460/490: Train Loss: 1.0300, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 461/490: Train Loss: 1.0278, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 462/490: Train Loss: 1.0284, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 463/490: Train Loss: 1.0407, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 464/490: Train Loss: 1.0342, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 465/490: Train Loss: 1.0430, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 466/490: Train Loss: 1.0294, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 467/490: Train Loss: 1.0483, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 468/490: Train Loss: 1.0466, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 469/490: Train Loss: 1.0323, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 470/490: Train Loss: 1.0298, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 471/490: Train Loss: 1.0374, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 472/490: Train Loss: 1.0328, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 473/490: Train Loss: 1.0441, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 474/490: Train Loss: 1.0335, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 475/490: Train Loss: 1.0497, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 476/490: Train Loss: 1.0385, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 477/490: Train Loss: 1.0491, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 478/490: Train Loss: 1.0448, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 479/490: Train Loss: 1.0312, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 480/490: Train Loss: 1.0514, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 481/490: Train Loss: 1.0322, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 482/490: Train Loss: 1.0362, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 483/490: Train Loss: 1.0284, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 484/490: Train Loss: 1.0342, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 485/490: Train Loss: 1.0307, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 486/490: Train Loss: 1.0288, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 487/490: Train Loss: 1.0306, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 488/490: Train Loss: 1.0364, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 489/490: Train Loss: 1.0296, Train Acc: 0.2952, Test Acc: 0.4222\n",
      "Epoch 490/490: Train Loss: 1.0531, Train Acc: 0.2952, Test Acc: 0.4222\n"
     ]
    }
   ],
   "source": [
    "optim  = torch.optim.SGD(mlp.parameters(), lr = 1e-2, weight_decay = 1e-4, momentum = 0.9)\n",
    "loss_fn = losses.CELoss()\n",
    "\n",
    "mlp, results = trainig_testing.train_and_evaluate(mlp, trainloader, testloader, optim, loss_fn, num_epochs = 490)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
